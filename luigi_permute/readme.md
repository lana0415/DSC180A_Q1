# DSC180A Quarter 1 Checkpoint

Folders given by mentor:
- `luigi_permute`: Ollama and luigi-based orchestration for single-prompt permutation experiments

Demo on Salary Negotiation:
- `salary.yml`: demo prompt to generate data
-  results and analysis notebook located in `luigi_permute/data/salary_negotiation/demo`

Quarter 1 Checkpoint:

- `major.yml`: my prompt to generate data on major advice
- `run_luigi_major.py`: script for creating database for results
- `results.db`: results generated by Ollama

To Reproduce Results:
- download Ollama and ensure it can be accessed via command prompt
- copy full repository
- DELETE `results.db` located in `luigi_permute/data/salary_negotiation`
- cd into `luigi_permute` folder
- Run the following commands:
  - ollama pull llama2:7b-chat-q4_K_M
  - ollama pull llama3:8b-instruct-q4_K_M
  - pip install -r requirements.txt
  - python3 run_luigi_major.py major.yml


Debugging:
- for verbose debugging: `python3 run_luigi.py --verbose salary.yml`
- to replace existing output file (specified in yml), otherwise will resume: `python3 run_luigi.py --replace salary.yml`

Notes for checkpoint:
- We just started to learn how to implement algorithm audits coding-wise. Just recently we were provided a demo on how to automate the process of feeding prompts to an LLM. For this checkpoint, I created my own prompt and edited/created new files accordingly to make this process work. Currently, we are using Ollama as it can run on our devices, but I plan to learn how to expand to other LLMs as Ollama is time-consuming and not as widely used. As we progress forward, I believe the code used for this project will become more rigorous. Looking at my current results, the LLM did not follow directions which makes it hard to do meaningful data analysis. If I were to use Ollama again, I would need to workshop the prompt and possibly the varying key information. 

